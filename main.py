import feedparser
import requests
import os
import datetime
from bs4 import BeautifulSoup

# --- C·∫§U H√åNH ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

# S·ªë l∆∞·ª£ng tin t·ªëi ƒëa cho m·ªói danh m·ª•c
LIMIT_PER_CAT = 20 

# C·∫§U H√åNH NGU·ªíN TIN V√Ä T·ª™ KH√ìA L·ªåC
# Code s·∫Ω qu√©t RSS, n·∫øu ti√™u ƒë·ªÅ ho·∫∑c m√¥ t·∫£ ch·ª©a keyword th√¨ m·ªõi l·∫•y.
# N·∫øu keywords ƒë·ªÉ r·ªóng [] th√¨ l·∫•y h·∫øt.
DANH_MUC = [
    {
        "ten": "üåç T√ÄI CH√çNH & KINH T·∫æ TH·∫æ GI·ªöI",
        "urls": [
            "https://cafef.vn/tai-chinh-quoc-te.rss",
            "https://vnexpress.net/rss/the-gioi.rss",
            "https://vneconomy.vn/timeline/9920/the-gioi.htm" # RSS gi·∫£ l·∫≠p
        ],
        "keywords": ["kinh t·∫ø", "t√†i ch√≠nh", "fed", "l√£i su·∫•t", "l·∫°m ph√°t", "gdp", "usd", "t·ª∑ gi√°", "trung qu·ªëc", "m·ªπ", "eu"]
    },
    {
        "ten": "üî• ƒê·ªäA CH√çNH TR·ªä & XUNG ƒê·ªòT",
        "urls": [
            "https://vnexpress.net/rss/the-gioi.rss",
            "https://thanhnien.vn/rss/the-gioi.rss"
        ],
        "keywords": ["xung ƒë·ªôt", "chi·∫øn tranh", "qu√¢n s·ª±", "bi·ªÉu t√¨nh", "b·∫ßu c·ª≠", "t·ªïng th·ªëng", "v≈© kh√≠", "nato", "bi·ªÉn ƒë√¥ng", "israel", "nga", "ukraine"]
    },
    {
        "ten": "üìà CH·ª®NG KHO√ÅN & T√ÄI CH√çNH VN",
        "urls": [
            "https://cafef.vn/tai-chinh-chung-khoan.rss",
            "https://vietstock.vn/rss/chung-khoan.rss",
            "https://vnexpress.net/rss/kinh-doanh.rss"
        ],
        "keywords": ["c·ªï phi·∫øu", "vn-index", "ch·ª©ng kho√°n", "ng√¢n h√†ng", "l·ª£i nhu·∫≠n", "thua l·ªó", "tr√°i phi·∫øu", "s√†n hose", "hnx", "b√°o c√°o"]
    },
    {
        "ten": "‚öñÔ∏è THU·∫æ & CH√çNH S√ÅCH M·ªöI",
        "urls": [
            "https://thuvienphapluat.vn/rss/van-ban-moi.xml",
            "https://vnexpress.net/rss/phap-luat.rss",
            "https://cafef.vn/vi-mo-dau-tu.rss"
        ],
        "keywords": ["thu·∫ø", "ngh·ªã ƒë·ªãnh", "th√¥ng t∆∞", "lu·∫≠t", "ch√≠nh ph·ªß", "ƒë·ªÅ xu·∫•t", "ban h√†nh", "quy ƒë·ªãnh", "ph·∫°t", "b·∫£o hi·ªÉm"]
    },
    {
        "ten": "üõí TH∆Ø∆†NG M·∫†I ƒêI·ªÜN T·ª¨ (E-COM)",
        "urls": [
            "https://cafebiz.vn/cong-nghe.rss",
            "https://vnexpress.net/rss/kinh-doanh.rss"
        ],
        "keywords": ["shopee", "lazada", "tiki", "tiktok", "th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠", "online", "b√°n l·∫ª", "livestream", "logistic", "giao h√†ng"]
    },
    {
        "ten": "‚úàÔ∏è DU L·ªäCH & XU H∆Ø·ªöNG",
        "urls": [
            "https://vnexpress.net/rss/du-lich.rss",
            "https://thanhnien.vn/rss/du-lich.rss"
        ],
        "keywords": [] # L·∫•y h·∫øt tin du l·ªãch, kh√¥ng c·∫ßn l·ªçc
    }
]

def clean_html(raw_html):
    # H√†m l√†m s·∫°ch th·∫ª HTML trong m√¥ t·∫£
    try:
        soup = BeautifulSoup(raw_html, "html.parser")
        text = soup.get_text(separator=" ")
        return text.strip()
    except:
        return raw_html

def rut_gon_van_ban(text, max_words=50):
    # C·∫Øt vƒÉn b·∫£n xu·ªëng c√≤n kho·∫£ng 50 t·ª´
    words = text.split()
    if len(words) > max_words:
        return " ".join(words[:max_words]) + "..."
    return text

def gui_telegram(ds_tin_nhan):
    for msg in ds_tin_nhan:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        # T·∫Øt ch·∫ø ƒë·ªô Markdown ƒë·ªÉ tr√°nh l·ªói k√Ω t·ª± ƒë·∫∑c bi·ªát, d√πng HTML ƒë∆°n gi·∫£n ho·∫∑c text th∆∞·ªùng
        data = {
            "chat_id": TELEGRAM_CHAT_ID, 
            "text": msg, 
            "disable_web_page_preview": True
        }
        requests.post(url, json=data)

def xu_ly_tin_tuc():
    ngay = datetime.datetime.now().strftime("%d/%m/%Y")
    # Tin nh·∫Øn m·ªü ƒë·∫ßu
    messages_queue = [f"üìÖ **T·ªîNG H·ª¢P TIN NG√ÄY {ngay}**\n(Tool t·ª± ƒë·ªông t·ªïng h·ª£p - Kh√¥ng d√πng AI)"]
    
    current_msg = ""
    
    for muc in DANH_MUC:
        header = f"\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\n**{muc['ten']}**\n"
        
        # N·∫øu th√™m header v√†o m√† qu√° d√†i th√¨ ng·∫Øt tin nh·∫Øn c≈©, t·∫°o tin m·ªõi
        if len(current_msg) + len(header) > 3500:
            messages_queue.append(current_msg)
            current_msg = header
        else:
            current_msg += header
            
        count = 0
        collected_links = set() # ƒê·ªÉ l·ªçc tin tr√πng nhau
        
        for url in muc['urls']:
            if count >= LIMIT_PER_CAT: break
            
            try:
                feed = feedparser.parse(url)
                for entry in feed.entries:
                    if count >= LIMIT_PER_CAT: break
                    
                    title = entry.title
                    link = entry.link
                    
                    # L·ªçc tr√πng l·∫∑p
                    if link in collected_links: continue
                    
                    # L·∫•y m√¥ t·∫£ (summary)
                    desc_raw = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
                    desc_clean = clean_html(desc_raw)
                    desc_short = rut_gon_van_ban(desc_clean, 50)
                    
                    # LOGIC L·ªåC T·ª™ KH√ìA
                    # N·∫øu danh m·ª•c c√≥ keywords, ph·∫£i check xem b√†i vi·∫øt c√≥ ch·ª©a t·ª´ kh√≥a ƒë√≥ kh√¥ng
                    keywords = muc.get('keywords', [])
                    if keywords:
                        text_to_check = (title + " " + desc_clean).lower()
                        # N·∫øu KH√îNG ch·ª©a t·ª´ kh√≥a n√†o trong list th√¨ b·ªè qua
                        if not any(k in text_to_check for k in keywords):
                            continue
                    
                    # T·∫°o n·ªôi dung tin
                    news_item = f"\nüîπ {title}\n_{desc_short}_\nüëâ {link}\n"
                    
                    # Ki·ªÉm tra ƒë·ªô d√†i tin nh·∫Øn
                    if len(current_msg) + len(news_item) > 3800: # Gi·ªõi h·∫°n an to√†n c·ªßa Tele l√† 4096
                        messages_queue.append(current_msg)
                        current_msg = news_item # B·∫Øt ƒë·∫ßu tin m·ªõi v·ªõi n·ªôi dung b√†i b√°o n√†y
                    else:
                        current_msg += news_item
                    
                    collected_links.add(link)
                    count += 1
            except Exception as e:
                print(f"L·ªói ƒë·ªçc RSS {url}: {e}")
                
        if count == 0:
            current_msg += "\n(Kh√¥ng c√≥ tin m·ªõi ph√π h·ª£p keyword h√¥m nay)\n"

    # ƒê·∫©y n·ªët ph·∫ßn c√≤n d∆∞ v√†o h√†ng ƒë·ª£i
    if current_msg:
        messages_queue.append(current_msg)
        
    return messages_queue

def main():
    if not TELEGRAM_TOKEN:
        print("Ch∆∞a c·∫•u h√¨nh Token!")
        return
        
    ds_tin = xu_ly_tin_tuc()
    gui_telegram(ds_tin)
    print("ƒê√£ g·ª≠i tin xong!")

if __name__ == "__main__":
    main()
