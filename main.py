import feedparser
import requests
import os
import datetime
import time
from time import mktime
from bs4 import BeautifulSoup

# --- C·∫§U H√åNH ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

# S·ªë l∆∞·ª£ng tin m·ªói m·ª•c
LIMIT_PER_CAT = 30 
DELETE_LIMIT = 200 

DANH_MUC = [
    {
        "ten": "üåç T√ÄI CH√çNH & KINH T·∫æ TH·∫æ GI·ªöI",
        "urls": [
            "https://cafef.vn/tai-chinh-quoc-te.rss",
            "https://vnexpress.net/rss/the-gioi.rss",
            "https://vneconomy.vn/timeline/9920/the-gioi.htm",
            "https://bnews.vn/rss/the-gioi.rss"
        ],
        "keywords": [
            "fed", "c·ª•c d·ª± tr·ªØ li√™n bang", "l√£i su·∫•t", "l·∫°m ph√°t", "gdp", "cpi", "pmi",
            "usd", "t·ª∑ gi√°", "y√™n nh·∫≠t", "nh√¢n d√¢n t·ªá", "eur", "v√†ng", "d·∫ßu", "nƒÉng l∆∞·ª£ng",
            "world bank", "imf", "ecb", "suy tho√°i", "kh·ªßng ho·∫£ng", "bitcoin", "crypto",
            "ch·ª©ng kho√°n m·ªπ", "wall street", "dow jones", "nasdaq", "s&p 500",
            "trung qu·ªëc", "kinh t·∫ø m·ªπ", "xu·∫•t kh·∫©u", "chu·ªói cung ·ª©ng"
        ]
    },
    {
        "ten": "üî• ƒê·ªäA CH√çNH TR·ªä & B·∫§T ·ªîN TO√ÄN C·∫¶U",
        "urls": [
            "https://vnexpress.net/rss/the-gioi.rss",
            "https://thanhnien.vn/rss/the-gioi.rss",
            "https://tuoitre.vn/rss/the-gioi.rss"
        ],
        "keywords": [
            "xung ƒë·ªôt", "chi·∫øn tranh", "qu√¢n s·ª±", "giao tranh", "t·∫•n c√¥ng", "kh·ªßng b·ªë",
            "bi·ªÉu t√¨nh", "b·∫°o lo·∫°n", "ƒë·∫£o ch√≠nh", "b·∫ßu c·ª≠", "t·ªïng th·ªëng", "th·ªß t∆∞·ªõng",
            "nato", "li√™n h·ª£p qu·ªëc", "bi·ªÉn ƒë√¥ng", "trung ƒë√¥ng", "gaza", "israel", "hamas",
            "ukraine", "nga", "tri·ªÅu ti√™n", "h·∫°t nh√¢n", "t√™n l·ª≠a", "v≈© kh√≠", "bi√™n gi·ªõi",
            "tr·ª´ng ph·∫°t", "c·∫•m v·∫≠n", "ngo·∫°i giao", "houthi", "bi·ªÉn ƒë·ªè"
        ]
    },
    {
        "ten": "üìà CH·ª®NG KHO√ÅN & T√ÄI CH√çNH VI·ªÜT NAM",
        "urls": [
            "https://cafef.vn/tai-chinh-chung-khoan.rss",
            "https://vietstock.vn/rss/chung-khoan.rss",
            "https://tinnhanhchungkhoan.vn/rss/chung-khoan.rss",
            "https://vneconomy.vn/timeline/6/chung-khoan.htm"
        ],
        "keywords": [
            "vn-index", "vnindex", "hnx", "upcom", "c·ªï phi·∫øu", "ch·ª©ng kho√°n", "thanh kho·∫£n",
            "kh·ªëi ngo·∫°i", "t·ª± doanh", "l·ª£i nhu·∫≠n", "thua l·ªó", "b√°o c√°o t√†i ch√≠nh", "c·ªï t·ª©c",
            "ng√¢n h√†ng", "b·∫•t ƒë·ªông s·∫£n", "tr√°i phi·∫øu", "ƒë√°o h·∫°n", "v·ªën h√≥a", "ipo",
            "nh·∫≠n ƒë·ªãnh", "ph√¢n t√≠ch", "khuy·∫øn ngh·ªã", "b·∫Øt ƒë√°y", "ch·ªët l·ªùi", "margin",
            "hpg", "vcb", "ssi", "vic", "vhm", "fpt", "mwg"
        ]
    },
    {
        "ten": "‚öñÔ∏è CH√çNH S√ÅCH THU·∫æ & LU·∫¨T",
        "urls": [
            "https://thuvienphapluat.vn/rss/van-ban-moi.xml",
            "https://vnexpress.net/rss/phap-luat.rss",
            "https://cafef.vn/vi-mo-dau-tu.rss",
            "https://tapchitaichinh.vn/co-che-chinh-sach.rss"
        ],
        "keywords": [
            "thu·∫ø", "vat", "thu·∫ø thu nh·∫≠p", "thu·∫ø tndn", "thu·∫ø tncn", "ho√†n thu·∫ø",
            "t·ªïng c·ª•c thu·∫ø", "b·ªô t√†i ch√≠nh", "h·∫£i quan", "ngh·ªã ƒë·ªãnh", "th√¥ng t∆∞", "lu·∫≠t",
            "ch√≠nh ph·ªß", "qu·ªëc h·ªôi", "d·ª± th·∫£o", "ban h√†nh", "quy ƒë·ªãnh m·ªõi", "x·ª≠ ph·∫°t",
            "h√≥a ƒë∆°n ƒëi·ªán t·ª≠", "ch√≠nh s√°ch t√†i kh√≥a", "gi·∫£m thu·∫ø", "mi·ªÖn thu·∫ø"
        ]
    },
    {
        "ten": "üõí TH∆Ø∆†NG M·∫†I ƒêI·ªÜN T·ª¨ (E-COM)",
        "urls": [
            "https://cafebiz.vn/cong-nghe.rss",
            "https://vnexpress.net/rss/kinh-doanh.rss",
            "https://vneconomy.vn/timeline/99/tieu-dung.htm"
        ],
        "keywords": [
            "th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠", "e-commerce", "mua s·∫Øm tr·ª±c tuy·∫øn", "online", "b√°n l·∫ª",
            "shopee", "lazada", "tiki", "tiktok shop", "amazon", "alibaba", "temu",
            "giao h√†ng", "logistic", "kho b√£i", "thanh to√°n", "v√≠ ƒëi·ªán t·ª≠", "momo", "zalopay",
            "livestream", "ch·ªët ƒë∆°n", "doanh thu online", "chuy·ªÉn ƒë·ªïi s·ªë"
        ]
    },
    {
        "ten": "üìä S·ªê LI·ªÜU & XU H∆Ø·ªöNG DU L·ªäCH",
        "urls": [
            "https://vnexpress.net/rss/du-lich.rss",
            "https://tcdulichphat.com/rss/home", 
            "https://baodautu.vn/du-lich.rss"
        ],
        "keywords": [
            "s·ªë li·ªáu", "th·ªëng k√™", "b√°o c√°o", "doanh thu", "l∆∞·ª£t kh√°ch", "kh√°ch qu·ªëc t·∫ø",
            "kh√°ch n·ªôi ƒë·ªãa", "l·ªØ h√†nh", "h√†ng kh√¥ng", "v√© m√°y bay", "c·ª•c du l·ªãch", "visa",
            "th·ªã th·ª±c", "mi·ªÖn visa", "xu h∆∞·ªõng", "c√¥ng su·∫•t ph√≤ng", "kh√°ch s·∫°n", "resort",
            "du l·ªãch b·ªÅn v·ªØng", "mice", "tƒÉng tr∆∞·ªüng", "s·ª•t gi·∫£m", "un tourism"
        ]
    }
]

def clean_html(raw_html):
    # --- C·∫¢I TI·∫æN M·ªöI ---
    try:
        # D√πng html.parser (c√≥ s·∫µn) ƒë·ªÉ tr√°nh l·ªói k√©n th∆∞ vi·ªán
        soup = BeautifulSoup(raw_html, "html.parser")
        
        # 1. H·ªßy di·ªát c√°c th·∫ª kh√¥ng mong mu·ªën (·∫¢nh, Script, Style, Iframe)
        for tag in soup(['script', 'style', 'img', 'iframe', 'video']):
            tag.decompose()
            
        # 2. L·∫•y text thu·∫ßn t√∫y
        text = soup.get_text(separator=" ")
        
        # 3. X·ª≠ l√Ω kho·∫£ng tr·∫Øng th·ª´a (bi·∫øn "   abc   " th√†nh "abc")
        text = " ".join(text.split())
        
        # 4. X√≥a c√°c c·ª•m t·ª´ r√°c th∆∞·ªùng g·∫∑p ·ªü ƒë·∫ßu tin
        garbage_phrases = ["TTO -", "(D√¢n tr√≠)", "VTV.vn -", "B√°o ƒê·∫ßu t∆∞ -"]
        for phrase in garbage_phrases:
            text = text.replace(phrase, "")
            
        return text.strip()
    except:
        return "" # N·∫øu l·ªói qu√° th√¨ tr·∫£ v·ªÅ r·ªóng ƒë·ªÉ ƒë·ª° r√°c m√†n h√¨nh

def convert_time(entry):
    try:
        if hasattr(entry, 'published_parsed'):
            dt_utc = datetime.datetime.fromtimestamp(mktime(entry.published_parsed))
            dt_vn = dt_utc + datetime.timedelta(hours=7)
            return dt_vn.strftime("%H:%M")
    except: pass
    return "M·ªõi"

def don_dep_chat():
    print("üßπ B·∫Øt ƒë·∫ßu d·ªçn d·∫πp...")
    url_send = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    try:
        resp = requests.post(url_send, json={"chat_id": TELEGRAM_CHAT_ID, "text": "‚è≥ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu..."}).json()
        if not resp.get("ok"): return

        current_id = resp['result']['message_id']
        for i in range(current_id, current_id - DELETE_LIMIT, -1):
            url_del = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/deleteMessage"
            requests.post(url_del, json={"chat_id": TELEGRAM_CHAT_ID, "message_id": i})
    except Exception as e:
        print(f"L·ªói d·ªçn d·∫πp: {e}")

def gui_theo_lo(ds_msg):
    for msg in ds_msg:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        
        # Chia nh·ªè n·∫øu qu√° d√†i
        if len(msg) > 4000:
            parts = [msg[i:i+4000] for i in range(0, len(msg), 4000)]
            for part in parts:
                requests.post(url, json={
                    "chat_id": TELEGRAM_CHAT_ID, 
                    "text": part, 
                    "disable_web_page_preview": True,
                    "parse_mode": "Markdown"
                })
                time.sleep(1)
        else:
            requests.post(url, json={
                "chat_id": TELEGRAM_CHAT_ID, 
                "text": msg, 
                "disable_web_page_preview": True, 
                "parse_mode": "Markdown"
            })
            time.sleep(1)

def xu_ly_tin_tuc():
    ngay = datetime.datetime.now().strftime("%d/%m/%Y")
    messages_queue = []
    messages_queue.append(f"üìÖ **B·∫¢N TIN NG√ÄY {ngay}**")
    
    current_msg = ""
    
    for muc in DANH_MUC:
        header = f"\n‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ‚ûñ\n**{muc['ten']}**\n"
        if len(current_msg) + len(header) > 3000:
            messages_queue.append(current_msg)
            current_msg = header
        else:
            current_msg += header
            
        count = 0
        collected_links = set()
        
        for url in muc['urls']:
            if count >= LIMIT_PER_CAT: break
            try:
                feed = feedparser.parse(url)
                for entry in feed.entries:
                    if count >= LIMIT_PER_CAT: break
                    link = entry.link
                    if link in collected_links: continue
                    
                    keywords = muc.get('keywords', [])
                    desc_raw = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
                    
                    # --- G·ªåI H√ÄM L√ÄM S·∫†CH M·ªöI ---
                    desc_clean = clean_html(desc_raw)
                    
                    # Ki·ªÉm tra t·ª´ kh√≥a
                    if keywords:
                        text_check = (entry.title + " " + desc_clean).lower()
                        if not any(k in text_check for k in keywords): continue
                    
                    time_str = convert_time(entry)
                    
                    # Format tin nh·∫Øn g·ªçn g√†ng: Ti√™u ƒë·ªÅ ƒë·∫≠m, M√¥ t·∫£ nghi√™ng
                    news_item = f"\nüïí `{time_str}` | **{entry.title}**\n_{desc_clean}_\nüëâ [Xem chi ti·∫øt]({link})\n"
                    
                    if len(current_msg) + len(news_item) > 3500:
                        messages_queue.append(current_msg)
                        current_msg = news_item 
                    else:
                        current_msg += news_item
                    
                    collected_links.add(link)
                    count += 1
            except: pass
            
        if count == 0:
            current_msg += "\n_(Kh√¥ng c√≥ tin m·ªõi)_\n"

    if current_msg:
        messages_queue.append(current_msg)
        
    return messages_queue

def main():
    if not TELEGRAM_TOKEN: return
    don_dep_chat()
    ds_tin = xu_ly_tin_tuc()
    gui_theo_lo(ds_tin)

if __name__ == "__main__":
    main()
